{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar las imagenes del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './chest_xray/train/'\n",
    "test_dir = './chest_xray/test/'\n",
    "val_dir = './chest_xray/val/'\n",
    "\n",
    "img_width = 160\n",
    "img_height = 160\n",
    "\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed = 123,\n",
    "    image_size = (img_width, img_height),\n",
    "    batch_size=None\n",
    ")\n",
    "\n",
    "test_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    seed = 123,\n",
    "    image_size = (img_width, img_height),\n",
    "    batch_size=None \n",
    ")\n",
    "val_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    seed = 123,\n",
    "    image_size = (img_width, img_height),\n",
    "    batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar las imagenes de entrenamiento y validación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train_data:\n",
    "    imagen = cv2.resize(feature.numpy(), (img_width, img_height))\n",
    "    imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "    imagen = imagen.reshape(img_width, img_height, 1)\n",
    "    x_train.append(imagen)\n",
    "    y_train.append(label.numpy())\n",
    "\n",
    "for feature, label in test_data:\n",
    "    imagen = cv2.resize(feature.numpy(), (img_width, img_height))\n",
    "    imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "    imagen = imagen.reshape(img_width, img_height, 1)\n",
    "    x_test.append(imagen)\n",
    "    y_test.append(label.numpy())\n",
    "    \n",
    "for feature, label in val_data:\n",
    "    imagen = cv2.resize(feature.numpy(), (img_width, img_height))\n",
    "    imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "    imagen = imagen.reshape(img_width, img_height, 1)\n",
    "    x_val.append(imagen)\n",
    "    y_val.append(label.numpy())\n",
    "\n",
    "X_fit = np.array(x_train)\n",
    "y_fit = np.array(y_train)\n",
    "X_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "X_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "X = np.concatenate((X_fit, X_test, X_val))\n",
    "y = np.concatenate((y_fit, y_test, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split para entrenamiento y validacion -\n",
    "Entrenamiento: 80%\n",
    "Validacion: 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entrenamiento = X[:4685]\n",
    "X_validacion = X[1171:]\n",
    "\n",
    "y_entrenamiento = y[:4685]\n",
    "y_validacion = y[1171:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumento de datos y arquitectura de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 160 #Tamaño de la imagen\n",
    "\n",
    "#Capa de redimensión\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(img_size, img_size),\n",
    "    tf.keras.layers.Rescaling(1./255)\n",
    "])\n",
    "#Capa de aumento de datos\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(factor=0.2),\n",
    "\n",
    "])\n",
    "#Capas convolucionales y densas\n",
    "modelo = tf.keras.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_augmentation, \n",
    "    \n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), padding='same'), \n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), padding='same'), \n",
    "        \n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2), padding='same'), \n",
    "        \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "modelo.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entremiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "\n",
    "history = modelo.fit(\n",
    "    X_entrenamiento,\n",
    "    y_entrenamiento,\n",
    "    validation_data = (X_validacion, y_validacion),\n",
    "    epochs = 20,\n",
    "    callbacks=[reduce_lr]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficas del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.title('Precisión de clasificación')\n",
    "plt.ylabel('Precisión')\n",
    "plt.xlabel('Numero de entrenamientos')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Número de entrenamientos')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend(loc='lower left')\n",
    "modelo.summary()\n",
    "tf.keras.utils.plot_model(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "[[0.97087379 0.2571977 ]\n",
      " [0.02912621 0.7428023 ]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.43      0.59       234\n",
      "           1       0.74      0.99      0.85       390\n",
      "\n",
      "    accuracy                           0.78       624\n",
      "   macro avg       0.86      0.71      0.72       624\n",
      "weighted avg       0.83      0.78      0.75       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prediction = modelo.predict(X_test)\n",
    "y_prediction = np.argmax(y_prediction, axis=1)\n",
    "conf_m = confusion_matrix(y_test, y_prediction , normalize='pred')\n",
    "print(conf_m)\n",
    "clas_r = classification_report(y_test, y_prediction)\n",
    "print(clas_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
